{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multiclass_20_ng.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsPHnktZvUeCzhCW+wfGgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjankraj/Shala/blob/main/multiclass_20_ng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXiXplqjdnUv",
        "outputId": "a6c9352c-8ac6-4838-bea4-0e6c8aea41e9"
      },
      "source": [
        "#Classification of 20_newsgroup consisting of around 20000 files with 20 classes  \r\n",
        "# Random Forrest, Naive bayes and LSTM\r\n",
        "\r\n",
        "#Mounting drive \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSj86iV2gaNR"
      },
      "source": [
        "# !unzip  \"/content/20_newsgroups.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrTgmanbdXmU"
      },
      "source": [
        "#After manually uploading zip file\r\n",
        "!unzip -u \"/content/20_newsgroups.zip\" -d \"/content/Internship/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxyXtbbwi8fU",
        "outputId": "0f437142-458f-4073-8b90-fa7e4137a844"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20_newsgroups.zip  Internship  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgg97b63eGnd"
      },
      "source": [
        "from os import listdir\r\n",
        "from os.path import isfile, join\r\n",
        "# import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM4sI9VEeOWM"
      },
      "source": [
        "my_path = \"/content/Internship/20_newsgroups\"\r\n",
        "\r\n",
        "#creating a list of folder names to make valid pathnames later\r\n",
        "folders = [f for f in listdir(my_path)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBlAvlAYeuQM",
        "outputId": "2b4a8263-e6e7-4fa7-f200-3f5bf91d08a2"
      },
      "source": [
        "folders"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp.os.ms-windows.misc',\n",
              " 'sci.med',\n",
              " 'talk.religion.misc',\n",
              " 'rec.sport.hockey',\n",
              " 'talk.politics.guns',\n",
              " 'comp.graphics',\n",
              " 'rec.autos',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.misc',\n",
              " 'talk.politics.mideast',\n",
              " 'alt.atheism',\n",
              " 'sci.electronics',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.motorcycles',\n",
              " 'misc.forsale',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'sci.space',\n",
              " 'sci.crypt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5CyFjoVfKSc",
        "outputId": "9d1ac887-92ab-4534-cdae-9e6b3cb270fd"
      },
      "source": [
        "print(len(folders))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqC06Irbs1Pn"
      },
      "source": [
        "#function to remove incompatible files\r\n",
        "import os\r\n",
        "import sklearn.datasets\r\n",
        "def find_incompatible_files(path):\r\n",
        "    \"\"\"\r\n",
        "    Finds the filenames that are incompatible with `CountVectorizer`. These files are usually not compatible with UTF8!\r\n",
        "    parameter `path` is the absolute or relative path of the training data's root directory.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    count_vector = sklearn.feature_extraction.text.CountVectorizer()\r\n",
        "    files = sklearn.datasets.load_files(path)\r\n",
        "    num = []\r\n",
        "    for i in range(len(files.filenames)):\r\n",
        "        try:\r\n",
        "            count_vector.fit_transform(files.data[i:i + 1])\r\n",
        "        except UnicodeDecodeError:\r\n",
        "            num.append(files.filenames[i])\r\n",
        "            os.remove(files.filenames[i])\r\n",
        "        except ValueError:\r\n",
        "            pass\r\n",
        "\r\n",
        "    return num\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4wTSL1EtzxP"
      },
      "source": [
        "#Removing incompatible files\r\n",
        "val = find_incompatible_files(my_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVY8oXoUHuBi",
        "outputId": "1692d4f3-cdf8-4342-f177-a581cdbaaf4b"
      },
      "source": [
        "#printing no. of incompatible files removed\r\n",
        "\r\n",
        "print(len(val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKf-cweofQZc"
      },
      "source": [
        "#creating a 2D list to store list of all files in different folders\r\n",
        "\r\n",
        "files = []\r\n",
        "for folder_name in folders:\r\n",
        "    folder_path = join(my_path, folder_name)\r\n",
        "    files.append([f for f in listdir(folder_path)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHz0QeWZfylM",
        "outputId": "cd9e37d0-d928-4fd3-ea80-21e2eff10505"
      },
      "source": [
        "#There is around 20000 files or data points to read from\r\n",
        "sum(len(files[i]) for i in range(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVbdp-atjSKV"
      },
      "source": [
        "pathname_list = []\r\n",
        "for fo in range(len(folders)):\r\n",
        "    for fi in files[fo]:\r\n",
        "        pathname_list.append(join(my_path, join(folders[fo], fi)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JT9rAI-jZXi",
        "outputId": "d88c075c-55ca-4680-a23c-5f9458556400"
      },
      "source": [
        "len(pathname_list)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4-kWBNOjbq0"
      },
      "source": [
        "#making an array containing the classes each of the documents belong to\r\n",
        "\r\n",
        "Y = []\r\n",
        "for folder_name in folders:\r\n",
        "    folder_path = join(my_path, folder_name)\r\n",
        "    num_of_files= len(listdir(folder_path))\r\n",
        "    for i in range(num_of_files):\r\n",
        "        Y.append(folder_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0OtSmZaji2Z",
        "outputId": "22203691-84c8-4088-db43-82953488ada4"
      },
      "source": [
        "len(Y)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cBaW3e7AFsy"
      },
      "source": [
        "# function for reading data\r\n",
        "\r\n",
        "def ps(doc):\r\n",
        "      f = open(doc)\r\n",
        "      data= f.read()\r\n",
        "      return str(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EizFX_xTF2Z5"
      },
      "source": [
        "#Reading & storing data from all the files \r\n",
        "\r\n",
        "import glob\r\n",
        "import os.path\r\n",
        "import string \r\n",
        "\r\n",
        "X_data = []\r\n",
        "\r\n",
        "for i in range(len(pathname_list)):\r\n",
        "  for file in glob.glob(pathname_list[i]):\r\n",
        "      \r\n",
        "      data = ps(file)\r\n",
        "      X_data.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uDdIgyOHLYi",
        "outputId": "6f2db5fe-0fac-456f-e381-51e7957471b4"
      },
      "source": [
        "print(len(X_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLXLrUBRHUaS",
        "outputId": "93692b05-3305-4665-f4ad-2d384e7bcbd2"
      },
      "source": [
        "#Sample of texts from one file \r\n",
        "\r\n",
        "print(X_data[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Xref: cantaloupe.srv.cs.cmu.edu comp.os.ms-windows.misc:9169 comp.os.ms-windows.apps:10962\n",
            "Newsgroups: comp.os.ms-windows.misc,comp.os.ms-windows.apps\n",
            "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!howland.reston.ans.net!bogus.sura.net!darwin.sura.net!news.udel.edu!bach.udel.edu!swyatt\n",
            "From: swyatt@bach.udel.edu (Stephen L Wyatt)\n",
            "Subject: Re: WinBench\n",
            "Message-ID: <C52pKx.JKE@news.udel.edu>\n",
            "Sender: usenet@news.udel.edu\n",
            "Nntp-Posting-Host: bach.udel.edu\n",
            "Organization: University of Delaware\n",
            "References: <1pq37s$9dq@seven-up.East.Sun.COM> <1pqp3rINNg85@hp-col.col.hp.com> <rick.734113494@sundance>\n",
            "Date: Tue, 6 Apr 1993 17:50:57 GMT\n",
            "Lines: 12\n",
            "\n",
            "Ok, so if everyone is cheating.. is there any tests that run some \n",
            "macro (to load a huge drawing, etc...) on the SAME machine that might \n",
            "then tell us what the REAL world results are?\n",
            "\n",
            "I mean, run the tests on the same machine with different video cards\n",
            "running word, excel, or something like that to see how fast the cards are?\n",
            "\n",
            "-- \n",
            "----------------------------------------------------------------------------\n",
            "swyatt@brahms.udel.edu  !!! no disclaimer...I blame everything on someone else \n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "JL8GwnYXJPVE",
        "outputId": "d370e5c4-b698-44d4-8a19-d9f81bb039fa"
      },
      "source": [
        "#Organising data in pandas dataframe to work with\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "df1 = pd.DataFrame(X_data, columns=['Text'])\r\n",
        "df2 = pd.DataFrame(Y, columns=['Labels'])\r\n",
        "\r\n",
        "df = pd.concat([df1, df2], axis=1)\r\n",
        "print(len(df))\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Xref: cantaloupe.srv.cs.cmu.edu comp.os.ms-win...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Newsgroups: comp.os.ms-windows.misc\\nPath: can...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Path: cantaloupe.srv.cs.cmu.edu!rochester!corn...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Newsgroups: comp.os.ms-windows.misc\\nPath: can...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text                   Labels\n",
              "0  Xref: cantaloupe.srv.cs.cmu.edu comp.os.ms-win...  comp.os.ms-windows.misc\n",
              "1  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  comp.os.ms-windows.misc\n",
              "2  Newsgroups: comp.os.ms-windows.misc\\nPath: can...  comp.os.ms-windows.misc\n",
              "3  Path: cantaloupe.srv.cs.cmu.edu!rochester!corn...  comp.os.ms-windows.misc\n",
              "4  Newsgroups: comp.os.ms-windows.misc\\nPath: can...  comp.os.ms-windows.misc"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKy9n1YsH2bZ",
        "outputId": "9bd42bef-31d8-46a7-ea8e-3e8fdd3c1a4d"
      },
      "source": [
        "# Cleaning the texts\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk import word_tokenize \r\n",
        "from nltk.stem.porter import PorterStemmer\r\n",
        "\r\n",
        "corpus = []\r\n",
        "\r\n",
        "for i in range(len(X_data)):\r\n",
        "    \r\n",
        "    review = re.sub('[^a-zA-Z]', ' ', df['Text'][i])\r\n",
        "    review = review.lower()\r\n",
        "    review = review.split()\r\n",
        "    ps = PorterStemmer()\r\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english')) and len(word)>3]\r\n",
        "    review = ' '.join(review)\r\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljaj6zCzgFiV"
      },
      "source": [
        "df.Text = corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TSxL0hv8cZDd",
        "outputId": "e3c68f6e-6a75-49bd-80eb-4d663ecf98b2"
      },
      "source": [
        "df.Labels = df.Labels.astype('category')\r\n",
        "df['Code'] = df.Labels.cat.codes\r\n",
        "df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xref cantaloup comp window misc comp window ap...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>path cantaloup magnesium club news ohio state ...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>newsgroup comp window misc path cantaloup news...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>path cantaloup rochest cornel batcomput munnar...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>newsgroup comp window misc path cantaloup news...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ... Code\n",
              "0  xref cantaloup comp window misc comp window ap...  ...    2\n",
              "1  path cantaloup magnesium club news ohio state ...  ...    2\n",
              "2  newsgroup comp window misc path cantaloup news...  ...    2\n",
              "3  path cantaloup rochest cornel batcomput munnar...  ...    2\n",
              "4  newsgroup comp window misc path cantaloup news...  ...    2\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho-9jphzZgyg"
      },
      "source": [
        "#List of all words after cleaning\r\n",
        "\r\n",
        "list_of_words = []\r\n",
        "\r\n",
        "for i in range(len(df['Text'])):\r\n",
        "  for word in df['Text'][i].split():\r\n",
        "    list_of_words.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3mRS_gbaO7m",
        "outputId": "9694bcdf-6fc7-4a0a-c36f-9df28006532b"
      },
      "source": [
        "#finding the number of unique words that we have extracted from the documents\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "np_list_of_words = np.asarray(list_of_words)\r\n",
        "words, counts = np.unique(np_list_of_words, return_counts=True)\r\n",
        "len(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msw9FDHHiS3M"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X = df.Text\r\n",
        "y = df.Code\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state = 123, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DXSEDf73GXY"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftgc3ga73Ie_"
      },
      "source": [
        "#defining accuracy function for evaluation of models\r\n",
        "\r\n",
        "def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\r\n",
        "    get_fit = pipeline.fit(X_train, y_train)\r\n",
        "    y_pred1 = get_fit.predict(X_test)\r\n",
        "    accuracy1 = accuracy_score(y_test, y_pred1)\r\n",
        "    y_pred2 = get_fit.predict(X_train)\r\n",
        "    accuracy2 = accuracy_score(y_train, y_pred2)\r\n",
        "    print(\"accuracy score for test: {0:.2f}%\".format(accuracy1*100))\r\n",
        "    # print(classification_report(y_test, y_pred1))\r\n",
        "    print(\"accuracy score for train: {0:.2f}%\\n\".format(accuracy2*100))\r\n",
        "    # print(classification_report(y_train, y_pred2))\r\n",
        "    return accuracy1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxgFw-rq3P1o"
      },
      "source": [
        "#Constructing a pipeline for model evaluation\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "cv = CountVectorizer(max_df=0.5, min_df=100)\r\n",
        "rf = RandomForestClassifier()\r\n",
        "n_features = np.arange(20000,25001,5000)\r\n",
        "\r\n",
        "def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, ngram_range=(1, 1), classifier=rf):\r\n",
        "    result = []\r\n",
        "    print(classifier)\r\n",
        "    print(\"\\n\")\r\n",
        "    for n in n_features:\r\n",
        "        vectorizer.set_params(max_features=n, ngram_range=ngram_range)\r\n",
        "        checker_pipeline = Pipeline([\r\n",
        "            ('vectorizer', vectorizer),\r\n",
        "            ('classifier', classifier)\r\n",
        "        ])\r\n",
        "        print(\"Test result for {} features\".format(n))\r\n",
        "        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\r\n",
        "        result.append((n,nfeature_accuracy))\r\n",
        "        #result contains test accuracy\r\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHjCy7IY5Ct3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "tfidf = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WOUVYc65IYn",
        "outputId": "8af87d52-0016-4a20-fa7e-ae1e58d4532a"
      },
      "source": [
        "print(\"Result for trigram by random forrest (Tfidf)\\n\")\r\n",
        "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result for trigram by random forrest (Tfidf)\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "\n",
            "\n",
            "Test result for 20000 features\n",
            "accuracy score for test: 93.37%\n",
            "accuracy score for train: 98.04%\n",
            "\n",
            "Test result for 25000 features\n",
            "accuracy score for test: 93.46%\n",
            "accuracy score for train: 98.04%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luNaLCEd-TSn"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "clf = MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL-FPJiO-W9f",
        "outputId": "7fbbe2d7-6592-4e7d-e54b-cdfacee30428"
      },
      "source": [
        "print(\"Result for trigram by naive bayes (Tfidf)\\n\")\r\n",
        "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3), classifier=clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result for trigram by naive bayes (Tfidf)\n",
            "\n",
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "\n",
            "\n",
            "Test result for 20000 features\n",
            "accuracy score for test: 90.85%\n",
            "accuracy score for train: 94.65%\n",
            "\n",
            "Test result for 25000 features\n",
            "accuracy score for test: 90.91%\n",
            "accuracy score for train: 94.66%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXfN6ggmhkLr"
      },
      "source": [
        "#Building multiclass classification LSTM model\r\n",
        "\r\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.callbacks import EarlyStopping\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDAewUvoKIRo",
        "outputId": "fc15ae03-6259-4a44-db65-2ecc01b85818"
      },
      "source": [
        "n_most_common_words = 25000\r\n",
        "max_len=500\r\n",
        "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\r\n",
        "tokenizer.fit_on_texts(df['Text'].values)\r\n",
        "sequences = tokenizer.texts_to_sequences(df['Text'].values)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "print('Found %s unique words.' % len(word_index))\r\n",
        "\r\n",
        "X = pad_sequences(sequences, maxlen=max_len)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 83755 unique words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F3jOl3vB6nP"
      },
      "source": [
        "Y = pd.get_dummies(df['Code']).values"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_CvXNzoK2i4"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=123, shuffle=True)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GguvPQV3MsPC"
      },
      "source": [
        "epochs = 20\r\n",
        "emb_dim = 128\r\n",
        "batch_size = 500\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5RFnceBNBWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "189e3b62-c54e-4b6d-f0ff-e8b2efedd712"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\r\n",
        "# model.add(SpatialDropout1D(0.4))\r\n",
        "model.add((LSTM(128, dropout=0.4, recurrent_dropout=0.4)))\r\n",
        "model.add(Dense(20, activation='softmax'))\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "clsi = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"auto\")])\r\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "24/24 [==============================] - 55s 2s/step - loss: 2.9889 - acc: 0.0984 - val_loss: 2.9015 - val_acc: 0.2482\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 52s 2s/step - loss: 2.8634 - acc: 0.2106 - val_loss: 2.6323 - val_acc: 0.1900\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 51s 2s/step - loss: 2.5086 - acc: 0.2392 - val_loss: 2.3063 - val_acc: 0.2074\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 52s 2s/step - loss: 2.2593 - acc: 0.3514 - val_loss: 2.0232 - val_acc: 0.3556\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 52s 2s/step - loss: 2.0136 - acc: 0.4126 - val_loss: 1.9138 - val_acc: 0.4125\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 51s 2s/step - loss: 1.7135 - acc: 0.5220 - val_loss: 1.8960 - val_acc: 0.4185\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 53s 2s/step - loss: 1.7189 - acc: 0.4965 - val_loss: 1.5313 - val_acc: 0.5162\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 54s 2s/step - loss: 1.2117 - acc: 0.6730 - val_loss: 1.1827 - val_acc: 0.5858\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 53s 2s/step - loss: 0.8869 - acc: 0.7377 - val_loss: 1.0542 - val_acc: 0.6243\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 53s 2s/step - loss: 0.7409 - acc: 0.7867 - val_loss: 0.8575 - val_acc: 0.7059\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 54s 2s/step - loss: 0.6190 - acc: 0.8163 - val_loss: 0.7933 - val_acc: 0.7233\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 55s 2s/step - loss: 0.6719 - acc: 0.7991 - val_loss: 0.9585 - val_acc: 0.6631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYo9ZG_IQaLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a33d7dd-f6e1-43e5-98d8-b91743914277"
      },
      "source": [
        "accr1 = model.evaluate(X_test, y_test)\r\n",
        "print('Test set\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(accr1[0], accr1[1]))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "156/156 [==============================] - 23s 145ms/step - loss: 0.9899 - acc: 0.6507\n",
            "Test set\n",
            " Loss: 0.990\n",
            " Accuracy: 0.651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPbp-wPcPAtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998f12f2-8a9e-49a6-d829-9fc443f796c8"
      },
      "source": [
        "accr2 = model.evaluate(X_train, y_train)\r\n",
        "print('Train set\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(accr2[0], accr2[1]))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "467/467 [==============================] - 69s 147ms/step - loss: 0.7040 - acc: 0.7657\n",
            "Train set\n",
            " Loss: 0.704\n",
            " Accuracy: 0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTLM3J1paxiP"
      },
      "source": [
        "#mapping word to document frequency for all unique words\r\n",
        "\r\n",
        "dictionary = {}\r\n",
        "\r\n",
        "for word in words:\r\n",
        "  n = 0\r\n",
        "  for i in range(len(df['Text'])):\r\n",
        "    for w in df['Text'][i].split():\r\n",
        "      if word==w:\r\n",
        "        n += 1\r\n",
        "        continue\r\n",
        "  dictionary[word] = n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiBkeH1tdd-u"
      },
      "source": [
        "#Sorting and building vocabulary for data\r\n",
        "import operator\r\n",
        "\r\n",
        "sorted_d = sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True)\r\n",
        "vocab_list = list(sorted_d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX0E5EKEhrWg"
      },
      "source": [
        "#Probability P(word|class) function\r\n",
        "\r\n",
        "def prob(word):\r\n",
        "  for i in range(20):\r\n",
        "    for j in range(len(df['Text']):\r\n",
        "      n = 0\r\n",
        "      m = 0\r\n",
        "        if df['Code'][j] ==i:\r\n",
        "          m += 1\r\n",
        "          for w in df['Text'][j]:\r\n",
        "            if word==w:\r\n",
        "            n += 1\r\n",
        "            continue       \r\n",
        "    print(\"Probability P({}|{}) is equal to {0:.2f}\".format(word, i, (n/m)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}