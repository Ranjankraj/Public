{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2_LoR_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOexYLhbNrZS3/0zDIEk21k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjankraj/Shala/blob/main/TF2_LoR_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1kcQfl7UPk6",
        "outputId": "97c447ae-c6f2-412d-cdab-264c2c68de53"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am379y9AU4ec"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZktrPk4JVmBP"
      },
      "source": [
        "num_classes = 10  #0 to 9 digits\r\n",
        "num_features = 784  #28*28"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNY8dOn2WENB"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "#convert data into float as we need W, b in float and originally, they are of int type\r\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\r\n",
        "\r\n",
        "#flatten images to 1D vector of 748 features (28*28)\r\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\r\n",
        "\r\n",
        "#normalize images to [0.0 to 1.0] from [0, 255]\r\n",
        "x_train, x_test = x_train/255. , x_test/255."
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdDCgpQFYPfM"
      },
      "source": [
        "# logistic regression model equation y = sigmoid(WX + b)\r\n",
        "def logistic_regression(X, W, b):\r\n",
        "    # apply softmax to normalize the logits to a probability distribution.\r\n",
        "    return tf.nn.softmax(tf.add(tf.matmul(X, W), b))\r\n",
        "\r\n",
        "# cross-entropy loss function\r\n",
        "def cross_entropy(y_pred, y_true):\r\n",
        "    # encode label to a one hot vector\r\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\r\n",
        "    # clip prediction values to avoid log(0) error\r\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\r\n",
        "    # compute cross-entropy\r\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), 1))\r\n",
        "\r\n",
        "# accuracy metric\r\n",
        "def accuracy(y_pred, y_true):\r\n",
        "    # predicted class is the index of highest score in prediction vector (i.e. argmax)\r\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\r\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9pMqSrdcoXm"
      },
      "source": [
        "# Stochastic Gradient Descent optimizer\r\n",
        "learning_rate = 0.01\r\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\r\n",
        "\r\n",
        "# optimization function\r\n",
        "def run_optimization(X, y, W, b):\r\n",
        "    # wrap computation inside a GradientTape for automatic differentiation\r\n",
        "    with tf.GradientTape() as g:\r\n",
        "        pred = logistic_regression(X, W, b)\r\n",
        "        loss = cross_entropy(pred, y)\r\n",
        "\r\n",
        "    # compute gradients\r\n",
        "    gradients = g.gradient(loss, [W, b])\r\n",
        "\r\n",
        "    # update W and b following gradients\r\n",
        "    optimizer.apply_gradients(zip(gradients, [W, b]))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvev-pF8dDFg",
        "outputId": "93dc9a32-cf34-43e2-ea94-244fa2e141c2"
      },
      "source": [
        "# training parameters\r\n",
        "batch_size = 256\r\n",
        "training_steps = 1000\r\n",
        "display_step = 50\r\n",
        "\r\n",
        "# use tf.data API to shuffle and batch data.\r\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\r\n",
        "\r\n",
        "# weight of shape [784, 10], the 28*28 image features, and total number of classes.\r\n",
        "W = tf.Variable(tf.ones([num_features, num_classes]), name=\"weight\")\r\n",
        "# bias of shape [10], the total number of classes.\r\n",
        "b = tf.Variable(tf.zeros([num_classes]), name=\"bias\")\r\n",
        "\r\n",
        "# run training for the given number of steps\r\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\r\n",
        "    # run the optimization to update W and b values\r\n",
        "    run_optimization(batch_x, batch_y, W, b)\r\n",
        "\r\n",
        "    # display optimization progress every few steps\r\n",
        "    if step % display_step == 0:\r\n",
        "        pred = logistic_regression(batch_x, W, b)\r\n",
        "        loss = cross_entropy(pred, batch_y)\r\n",
        "        acc = accuracy(pred, batch_y)\r\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\r\n",
        "    \r\n",
        "    # stop with specific accuracy criteria\r\n",
        "    #if acc > CONST:\r\n",
        "    #    break"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step: 50, loss: 1.868433, accuracy: 0.714844\n",
            "step: 100, loss: 1.572342, accuracy: 0.832031\n",
            "step: 150, loss: 1.336132, accuracy: 0.816406\n",
            "step: 200, loss: 1.205417, accuracy: 0.812500\n",
            "step: 250, loss: 1.120483, accuracy: 0.808594\n",
            "step: 300, loss: 0.949352, accuracy: 0.832031\n",
            "step: 350, loss: 0.933055, accuracy: 0.816406\n",
            "step: 400, loss: 0.840989, accuracy: 0.843750\n",
            "step: 450, loss: 0.747231, accuracy: 0.890625\n",
            "step: 500, loss: 0.812020, accuracy: 0.843750\n",
            "step: 550, loss: 0.720981, accuracy: 0.843750\n",
            "step: 600, loss: 0.704919, accuracy: 0.867188\n",
            "step: 650, loss: 0.694608, accuracy: 0.863281\n",
            "step: 700, loss: 0.629784, accuracy: 0.890625\n",
            "step: 750, loss: 0.795430, accuracy: 0.835938\n",
            "step: 800, loss: 0.641923, accuracy: 0.867188\n",
            "step: 850, loss: 0.657243, accuracy: 0.851562\n",
            "step: 900, loss: 0.756264, accuracy: 0.828125\n",
            "step: 950, loss: 0.600320, accuracy: 0.863281\n",
            "step: 1000, loss: 0.576246, accuracy: 0.871094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDI7O0GkfSPp",
        "outputId": "f107ce1f-41e2-40a3-b566-0f1cb38544a0"
      },
      "source": [
        "# In the above optput, the accuracy improves and then declines because of using SGD as it takes only 1 data point at each epoch\r\n",
        "# test model on validation set\r\n",
        "pred = logistic_regression(x_test, W, b)\r\n",
        "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.869000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "vMGX5J9xgy1R",
        "outputId": "85a70535-6582-4526-86f2-dec6d97c2349"
      },
      "source": [
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# set up matplotlib fig, and size it to fit 3x4 pics\r\n",
        "nrows = 1\r\n",
        "ncols = 5\r\n",
        "fig = plt.gcf()\r\n",
        "fig.set_size_inches(ncols*4, nrows*4)\r\n",
        "\r\n",
        "# predict images from validation set\r\n",
        "n_images = 5\r\n",
        "test_images = x_test[:n_images]\r\n",
        "predictions = logistic_regression(test_images, W, b)\r\n",
        "\r\n",
        "# visualize image and model prediction\r\n",
        "for i in range(n_images):\r\n",
        "    # set up subplot; subplot indices start at 1\r\n",
        "    sp = plt.subplot(nrows, ncols, i + 1, title=\"pred: %i\" % np.argmax(predictions.numpy()[i]))\r\n",
        "    sp.axis('Off') # don't show axes (or gridlines)\r\n",
        "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}